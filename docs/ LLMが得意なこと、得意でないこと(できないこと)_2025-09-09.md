```markdown
# 調査項目：LLMが得意なこと・得意でないこと（できないこと）

---

## 概要
LLM（大規模言語モデル）は、大量のテキストデータを使って学習し、自然言語処理を高度に行うAIモデルです。ChatGPTなどの生成AIの根幹技術として注目されています。LLMは文章の理解や生成に優れており、多くの場面で役立つ一方で、苦手とするタスクや限界も存在します。本資料では、最新の知見に基づき「得意なこと」と「得意でないこと」を体系的に整理します。

---

## 1. LLMが得意なこと

### 1-1. 単純作業・定型的タスクの自動化
- 形式が崩れたテキストから構造化データ（JSON、CSVなど）への変換
- OCR結果のテキスト整理や名刺・レシート情報の抽出
- 感情分析やテキストの分類（例：肯定・否定判定、ラベル付け）

**具体例**  
- レシートのOCRテキストを商品名・価格・数量に分けて整理  
- ソーシャルメディア投稿の感情を自動判定しマーケティングに活用  

### 1-2. 単純知識の提供・説明
- 教科書的な知識の提示（例：「三平方の定理とは？」「ExcelのIF関数の使い方」）
- FAQ対応や一般的な質問回答（検索エンジンの代替としても機能）

**具体例**  
- 「第二次世界大戦はいつ始まりましたか？」への回答  
- 製品マニュアルの基礎的な説明の自動生成  

### 1-3. 文章生成・編集・要約
- ブログ記事やメール下書きの作成  
- 文章のリライトや要約  
- 機械翻訳（ただし専門分野は注意が必要）

**具体例**  
- 製品紹介記事の自動執筆サポート  
- 長文のニュース記事を短く要約して提示  

### 1-4. 自然な対話・コミュニケーション
- ユーザーとのチャットによる対話応答  
- カスタマーサポートボット  
- コード生成や修正の提案

**具体例**  
- カスタマーサービスでの一次対応チャットボット  
- 開発者からの「特定の関数の書き方を教えて」に対するコード例の提示  

### 1-5. 言語理解に基づく様々な応用
- 固有表現抽出（人名や地名などの認識）  
- テキストマイニングや文章のトピック抽出  
- Transformerに基づく文脈理解と高度な言語解析  

---

## 2. LLMが得意でないこと・できないこと

### 2-1. 最新情報の即時反映・リアルタイム知識更新が苦手
- 学習済みの知識は静的（学習時点まで）であり、最新のニュースや技術を自力で取り込めない  
- リアルタイムで変化する情報に対応するには外部API連携など付加的な仕組みが必要  

**具体例**  
- 最新の政治的事件や新型感染症の最新情報を正確に答えられない  
- 日々変わる株価や天気情報の提供は不可（別システム連携必要）  

### 2-2. 厳密な論理的推論や専門的な知識の深堀りが苦手
- 複雑な数学問題や専門的・高度な分野の議論には誤りや不整合が起こりやすい  
- 専門家の判断や検証を完全に代替できるレベルには達していない  

**具体例**  
- 量子物理学の詳細な計算や医学論文の批判的解析は困難  
- 法律文書の厳密な解釈や契約書の作成には誤りを含む恐れがある  

### 2-3. 幻覚（ハルシネーション）の発生
- 実際には存在しない情報をあたかも真実かのように生成することがある  
- 特に根拠情報が乏しい事柄や曖昧な質問に対して誤情報が紛れ込みやすい  

**具体例**  
- 存在しない人物や文献を作りだしてレポートを生成  
- 偽の統計情報や事実誤認を含む回答をすることがある  

### 2-4. 感覚的・身体的な理解や経験ベースの判断
- 五感（視覚・聴覚・触覚・嗅覚・味覚）による理解ができない  
- 実体験や身体的感覚に基づく表現や判断が困難  

**具体例**  
- 手触りや味の感想の本質的な理解・説明は不可  
- 実際の現場感覚を要する感情やニュアンスの把握は不十分  

### 2-5. 長文の一貫性保持や複雑な構造の処理が限定的
- 非常に長い文章やドキュメントの全体を完全に把握し、一貫した内容を保つことが難しい  
- 大量の情報からの厳密なクロスチェックや複雑な論理構築には限界あり  

**具体例**  
- 長編小説の全体プロットを破綻なく生成するのは難しい  
- 複数の長文間の矛盾を検出・是正する能力は限定的  

### 2-6. 倫理的・社会的な問題対応やバイアス問題
- 偏見やステレオタイプを含む発言をしてしまうことがある  
- 差別的表現や不適切な内容を自動的に回避するには注意が必要  

**具体例**  
- 性別や人種に関する偏った表現を生成する可能性  
- 社会的にセンシティブな話題で誤情報や偏向が出る恐れ  

---

## 3. まとめ

| 項目             | 得意なこと                                                 | 苦手・できないこと                                         |
|------------------|------------------------------------------------------------|------------------------------------------------------------|
| **タスク例**       | 文章生成・編集、要約、翻訳、感情分析、質問応答、情報構造化     | 最新情報の反映、厳密な論理推論、専門的判断、幻覚現象          |
| **知識面**         | 学習データ内の豊富な知識を活用した一般的知識の提供              | 最新ニュース・技術動向のキャッチアップができない               |
| **理解力**         | 文脈理解・自然な言語表現生成                                 | 五感や実体験に基づいた理解・処理                               |
| **応答品質**       | 短〜中程度の文章で高い一貫性と自然さ                           | 長文の一貫性保持が難しい場合あり                              |
| **社会性・倫理性** | 指示学習やフィルタリングで不適切表現を減らすことが可能          | バイアス混入や不適切発言の完全排除はまだ課題                   |

---

## 4. 補足：今後の技術動向

- **継続学習・オンライン更新**：最新情報対応を進めるため学習方法の革新や外部情報連携が進行中
- **多モーダルモデル（LMM）**：画像・音声情報も扱う拡張版モデルの登場により、感覚的理解や多様な情報の統合が期待できる
- **ハルシネーション対策**：事実検証や信頼できる情報の参照技術による誤生成抑制が重要課題
- **倫理的AIの開発**：バイアス除去や社会的責任を伴うAI運用ルールの整備が進んでいる

---

## 参考情報

- [Qiita「LLMのできることとできないことを整理してみた」](https://qiita.com/)  
- [AIコンパス - 大規模言語モデルの能力創発と課題](https://ai-compass.weeybrid.co.jp/llm/)  
- [リコーお役立ちコラム：LLMとは何か？](https://www.ricoh.co.jp/)  
- [ChatGPTが不得意なこと｜Omicron note](https://note.com/omicron-ai)  

---

以上のように、LLMは大量テキストからの言語処理が得意で、多くの実務に対応可能ですが、情報の最新性や高度専門性、感覚的判断など、未だ課題や限界が存在します。活用時はその特性を理解し、適切な役割分担で用いることが重要です。
```