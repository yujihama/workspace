```markdown
# How large language models encode theory-of-mind: a study on sparse parameter patterns

## 概要
本論文は、大規模言語モデル（LLMs）がどのようにして**心の理論（Theory-of-Mind, ToM）**能力を獲得するかを、モデル内部の非常にまばらなパラメータパターンの観点から解明した研究です。

- **ToM-sensitiveパラメータ**（心の理論に特に敏感なパラメータ）を特定する新しい方法を提案。
- 全パラメータのわずか0.001%を操作するだけで、ToM性能が大きく低下し、文脈の位置特定能力や言語理解にも悪影響が出ることを発見。
- これらのパラメータは特にRoPE（Rotary Position Embedding）を使った**位置エンコーディング**モジュールと強く関連し、操作すると主に周波数特性が乱れ、注意機構のクエリとキー間の角度関係を変化させて注意の集中点を不安定化させる。

---

## 1. 背景と目的

### 心の理論（ToM）とは
- 他者の心的状態（信念、意図、感情など）を推測し理解する能力。
- 心理学や発達障害研究で重要な指標となる。
- 例：中身が「チョコレート」とラベルされた袋に実はポップコーンが入っている場合、登場人物は袋にチョコが入っていると誤信していることを推測できるか。

### LLMにおけるToMの重要性
- どのようにToM能力がLLMの中で形成されるかを理解することは、AIの社会的知性や信頼性を高める鍵。
- 従来の研究はタスクレベルでの性能評価が中心で、内部メカニズムの解析は不足。

### 本研究の課題
- ToM能力に関与する**特定パラメータの検出**
- それらがToM推論性能に与える影響の解析

---

## 2. 研究手法

### ToMタスクの設定
- 主に誤信念課題（False Belief Task）を評価指標として使用。
  - **予期しない内容タスク**：誤った内容表示に基づく信念推論。
  - **予期しない移動タスク**：物体の移動を知らないエージェントの行動予測。
- テストでは、文脈＋質問を入力し、返答から推論能力を判定。

### ToM-sensitiveパラメータの識別法
- モデルパラメータ（特に線形変換行列）に対し、**ヘッセ行列（またはフィッシャー情報行列）**による感度解析を実施。
- 感度の高いパラメータを0.001%の極めてまばらな集合として抽出。
- そのパラメータだけを平均値で置換する**摂動**を行い、ToM能力の変化を観察。
- 対照群としてランダムな同数のパラメータも摂動。

### 対象モデル
- Llama、Qwen、DeepSeek、Jambaなど、RoPEを利用するモデルと非利用モデルの両者で比較。

---

## 3. 主な結果

### 3.1 ToM能力とパラメータの関係
- わずかなToM-sensitiveパラメータの摂動だけで、ToM性能が大幅に低下。
- ランダムなパラメータ摂動では性能低下なし。
- ToM能力はモデルの**文脈位置特定能力**や**言語理解**とも連動。

### 3.2 ToM-sensitiveパラメータの特徴
- 主に**注意機構のWQ（クエリ行列）・WK（キー行列）**に固まる。
- これらは低ランクかつ周波数特性（RoPEに基づく位置エンコーディングの主導周波数）を強く制御。
- RoPE非使用モデル（例：Jamba）はこの周波数特性を持たず、異なる結果に。

### 3.3 RoPEの役割と摂動の影響
- RoPEはトークン間の相対的な位置信号を周波数的に埋め込み、注意の重み付けに影響。
- ToM-sensitiveパラメータ摂動により主導周波数信号が損なわれ、文脈の正しい位置付けが困難に。
- 摂動により、注意機構におけるクエリベクトルと「シーケンス開始（BOS）キー」ベクトルの角度が変化し、**attention sink（注意の集中点）**が不安定化。
- これにより注意マップが歪み、言語理解やToM推論に悪影響。

---

## 4. 議論と今後の展望

### 社会的推論の基盤
- ToMはLLM内部で局所的かつ低ランクなパラメータに依存した能力である。
- RoPEによる位置情報の構造化がToMの推論基盤となっている可能性が高い。

### 意義と応用
- モデル解釈性が向上し、ToM能力制御やアライメント（人間の倫理観との整合）に応用可能。
- ToM能力が一部のパラメータに集中しているため、悪意ある摂動や攻撃に弱いリスクも指摘。

### 今後の課題
- より幅広い社会的推論タスクへの適用と検証。
- ヒト脳におけるToMとの比較研究。
- 他のモダリティ（例：視覚質問応答）への拡張。
- ToM能力強化や防御・制御技術の開発。

---

## 5. まとめ

| ポイント                         | 内容                                                               |
|---------------------------------|--------------------------------------------------------------------|
| ToM-sensitiveパラメータ          | 0.001%未満の極めてまばらなパラメータで構成される　　　　　　                  |
| 影響範囲                        | ToM性能低下、文脈位置特定精度低下、言語理解能力低下                         |
| 位置エンコーディングとの関係     | RoPEベースの周波数特性を制御し、摂動で主導周波数信号が乱れる                      |
| 注意機構への波及                | クエリとBOSキーの角度を変化させ、attention sinkを不安定にする                  |
| RoPE非使用モデルの特徴           | 周波数依存性がなく、異なる敏感パターンを持つ                                   |
| 研究の意義                     | AIのToM機能の内部メカニズム解明と制御への第一歩、社会的知性の構造的理解の深化         |

---

## 付録・補足資料・データ・コード

- データセット：Hugging Face（MMLU等）およびOSF公開
- コードリポジトリ：[GitHub](https://github.com/joel-wu/how-large-language-models-encode-theory-of-mind)
- 詳細な数理解析は論文中「Methods」「Supplementary Information」を参照

---

## 参考文献抜粋（一部）

1. Premack & Woodruff (1978) — 原典的ToM論文  
2. Kosinski (2024) — LLMにおけるToM評価  
3. Su et al. (2021) — RoPE positional encodingの提案

---

本研究は、LLMが人間の社会的推論能力に類似した機能をどのように内部表現として獲得しているのか、極めて限られたパラメータの振る舞いから解明し、AIと認知科学の融合的理解を進めています。
```